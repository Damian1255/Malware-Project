{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file is used to merge the extracted traits from the traits folder into a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Working Directories\n",
    "IMPORTANT: Ensure that the working directories exist and are correctly defined before running the code. Also ensure traits are in `.joblib` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directories\n",
    "\n",
    "# Where the raw extracted traits are stored\n",
    "traits_folder_loc = 'traits'\n",
    "\n",
    "# Where would each splits of the data be stored\n",
    "raw_output_folder_loc = '../data/raw'\n",
    "\n",
    "# Where would the merged data be stored\n",
    "output_folder_loc = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data for Processing\n",
    "\n",
    "`n_splits` of 10 will split the data into 10 parts for processing. This is useful for large datasets that may not fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 10 parts for easier processing (due to memory constraints)\n",
    "n_split = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4048"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the traits folder\n",
    "traits = os.listdir(traits_folder_loc)\n",
    "total_count = len(traits)\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part 1 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 2 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 3 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 4 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 5 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 6 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 7 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 8 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 9 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 10 of 10\n",
      "Progress: 100.00% (404/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processing part 11 of 10\n",
      "Progress: 1.98% (8/404)\n",
      "Saving to CSV...\n",
      "\n",
      "Processed 4048 traits\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of traits per part (do no change)\n",
    "split = total_count // n_split\n",
    "count = 0\n",
    "part_count = 0\n",
    "\n",
    "for i in range(0, total_count, split):\n",
    "    part_count += 1\n",
    "    part = traits[i:i + split]\n",
    "\n",
    "    # Create a dataframe to store the trait data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    print(f'Processing part {part_count} of {n_split}')\n",
    "    count = 1\n",
    "\n",
    "    # Loop through the traits\n",
    "    for trait in part:\n",
    "        print(f'Progress: {count / split * 100:.2f}% ({count}/{split})', end='\\r')\n",
    "\n",
    "        # Load the trait data\n",
    "        trait_data = joblib.load(f'{traits_folder_loc}/{trait}')\n",
    "\n",
    "        # Add the trait data to the dataframe\n",
    "        df = pd.concat([df, trait_data])\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Save the dataframe\n",
    "    print('\\nSaving to CSV...\\n')\n",
    "    df.to_csv(f'{raw_output_folder_loc}/part_{part_count}.csv', index=False)\n",
    "\n",
    "print(f'Processed {total_count} traits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the data into a into a single dataset saved to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part_1.csv\n",
      "Processing part_10.csv\n",
      "Processing part_11.csv\n",
      "Processing part_2.csv\n",
      "Processing part_3.csv\n",
      "Processing part_4.csv\n",
      "Processing part_5.csv\n",
      "Processing part_6.csv\n",
      "Processing part_7.csv\n",
      "Processing part_8.csv\n",
      "Processing part_9.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine the csv files into one dataframe\n",
    "datafiles = os.listdir(raw_output_folder_loc)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for csv in datafiles:\n",
    "    print(f'Processing {csv}')\n",
    "    df = pd.read_csv(f'{raw_output_folder_loc}/{csv}')\n",
    "    data = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26925357, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined data\n",
    "data.to_csv(f'{output_folder_loc}/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
