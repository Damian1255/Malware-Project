"""

This script extracts the traits of the files in the specified root folder
and saves them to a joblib file. This script is meant to be run using the subprocessor.py

IMPORTANT: Ensure that the root folder and its subfolders exist before running this script.

"""

import os
import sys
import joblib
import pybinlex
import pandas as pd

# Specify if you want to switch to extract test data (set extrac_from_dir to 'binlex/malwares/Test')
extract_test_data = False
test_data_dir = 'binlex/data/test_data'

# Specify the root folder name (Ensure these folders/subfolders and its files exist)
extract_from_dir = 'binlex/malwares/Train'
extract_to_dir = 'binlex/extractor/traits'
log_dir_loc = 'binlex/extractor/logs/failed_logs.txt'

# Resume mode (Allows for automatic resume from the last failed log, do not change)
resume_mode = False

# Get the failed logs
failed_logs = []
with open(log_dir_loc, 'r') as f:
    failed_logs = f.read().splitlines()

# Check if 'END' is in the failed logs to stop the script
if 'END' in failed_logs:
    print('\nAll files have been processed')
    sys.exit()

# Automatically resume from the last failed log
if len(failed_logs) > 0:
    resume_mode = True
    last_line = failed_logs[-1].split('\\')
    resume_extract_from_dir = last_line[1]
    resume_file_name = last_line[-1]

# Check if the specified root folder exists
files = os.listdir(extract_from_dir)

# Iterate through the files in the root folder
for file in files:

    # Skip if resume mode is enabled and the current folder is not the last failed folder
    if resume_mode and file != resume_extract_from_dir:
        continue
    
    # Get the path of the file
    file_path = os.path.join(extract_from_dir, file)

    # Skip if the item is not a folder
    if not os.path.isdir(file_path):
        continue

    # Get all the items in the folder
    items = os.listdir(file_path)

    for item in items:
        # Skip if resume mode is enabled and the current file is not the last failed file
        if resume_mode and item != resume_file_name:
            continue
        else:
            resume_mode = False

        try:
            item_path = os.path.join(file_path, item)

            # Skip if is in the failed logs or in the blacklist
            if item_path in failed_logs:
                continue

            print(f'\nExtracting traits from: {item_path}')

            # Write directory to fail logs
            with open(log_dir_loc, 'a') as f:
                f.write(item_path + '\n')

            # Read the file
            pe = pybinlex.PE()
            result = pe.read_file(item_path)

            # Disassemble the file
            disassembler = pybinlex.Disassembler(pe)
            disassembler.disassemble()

            # Get the traits of the file
            traits = disassembler.get_traits()
            
            # Convert the traits to a pandas DataFrame
            df = pd.DataFrame(traits)
            
            # Append the folder name to the DataFrame
            df['family'] = file
            df['file_name'] = item

            # Drop the unnecessary columns
            df.drop(['tags', 'bytes_sha256', 'bytes_entropy', 'trait_sha256', 'mode', 'trait_tlsh'], axis=1, inplace=True)   
            
            if extract_test_data:
                # Create the test data directory if it does not exist
                if not os.path.exists(f'{test_data_dir}/{file}'):
                    os.makedirs(f'{test_data_dir}/{file}')

                # Save the new DataFrame to a joblib file
                joblib.dump(df, f'{test_data_dir}/{file}/{file}_{item}.joblib')
            else:
                # Remove duplicate rows
                df.drop_duplicates(inplace=True)

                # Save the new DataFrame to a joblib file
                joblib.dump(df, f'{extract_to_dir}/{file}_{item}.joblib')

            print(f'Success')

            # Remove the last row in the failed logs
            with open(log_dir_loc, 'r') as f:
                lines = f.read().splitlines()

            # Remove the last line
            lines = lines[:-1]

            # Write the new failed logs
            with open(log_dir_loc, 'w') as f:
                for line in lines:
                    f.write(line + '\n')
    
        except Exception as e:
            print(f'Error: {e}')
            continue


with open(log_dir_loc, 'a') as f:
    # write 'END' to the failed logs
    f.write('END\n')
