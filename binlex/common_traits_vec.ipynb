{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pybinlex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18390865, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family\n",
       "Khalesi      4379936\n",
       "Ekstak       4023486\n",
       "Bingoml      2988560\n",
       "AutoIt       2499728\n",
       "Sytro        1852566\n",
       "Allaple      1015743\n",
       "Mydoom        758110\n",
       "AntiFW        309246\n",
       "Picsys        299044\n",
       "Agentc        203668\n",
       "Vtflooder      15949\n",
       "Debris         15834\n",
       "Starter        15814\n",
       "RTM            11055\n",
       "BadCrypt        2126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top n traits Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_n_traits_vec(traits_db, top_n=200):\n",
    "    \n",
    "    # for each family, get the top n traits that are most frequent in that family\n",
    "    for family in traits_db['family'].unique():\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "\n",
    "        # get the top n traits for the family\n",
    "        family_traits = traits_db[traits_db['family'] == family]['trait']\n",
    "        result = family_traits.value_counts().head(top_n)\n",
    "        traits = result.index.tolist()\n",
    "\n",
    "        # vectorize traits\n",
    "        vect = vectorizer.fit_transform(traits)\n",
    "\n",
    "        # save vectorized traits to dataframe\n",
    "        result_df = pd.DataFrame(vect.toarray())\n",
    "\n",
    "        # create family directory if it does not exist\n",
    "        if not os.path.exists(f'data/vectors/{family}'):\n",
    "            os.makedirs(f'data/vectors/{family}')\n",
    "        \n",
    "        # save vectorizer and vectors to disk\n",
    "        joblib.dump(vectorizer, f'data/vectors/{family}/vectorizer_' + family + '.pkl')\n",
    "        result_df.to_csv(f'data/vectors/{family}/vectors_' + family + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traits Processing and Analyzing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_traits(sample_traits, top_n_traits, drop_duplicates=False):\n",
    "    # drop duplicates\n",
    "    if drop_duplicates:\n",
    "        sample_traits = sample_traits.drop_duplicates()\n",
    "        return sample_traits\n",
    "\n",
    "    # get top n traits\n",
    "    sample_traits = sample_traits['trait'].value_counts().head(top_n_traits)\n",
    "\n",
    "    # format the results\n",
    "    sample_traits = pd.DataFrame(sample_traits)\n",
    "    sample_traits.columns = ['count']\n",
    "    sample_traits['trait'] = sample_traits.index\n",
    "    sample_traits = sample_traits.reset_index(drop=True)\n",
    "    sample_traits = sample_traits[['trait', 'count']]\n",
    "\n",
    "    return sample_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_traits(sample_traits, vector_folder_loc):\n",
    "    results = {}\n",
    "    vector_folder = os.listdir(vector_folder_loc)\n",
    "\n",
    "    for family in vector_folder:\n",
    "        # load the vectorizer and vectors\n",
    "        vectorizer = joblib.load(f'{vector_folder_loc}/{family}/vectorizer_{family}.pkl')\n",
    "        vectors = pd.read_csv(f'{vector_folder_loc}/{family}/vectors_{family}.csv')\n",
    "\n",
    "        # vectorize the sample traits\n",
    "        sample_vector = vectorizer.transform(sample_traits['trait'])\n",
    "\n",
    "        # get the cosine similarity\n",
    "        similarity = cosine_similarity(sample_vector, vectors)\n",
    "        \n",
    "        results[family] = np.mean(similarity)\n",
    "\n",
    "    results = pd.DataFrame(results.items(), columns=['family', 'similarity'])\n",
    "    results = results.sort_values(by='similarity', ascending=False)\n",
    "    results = results.reset_index(drop=True)\n",
    "    \n",
    "    return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top n traits\n",
    "extract_top_n_traits_vec(df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating family: Agentc\n",
      "Progress: 100.0% (20/20) - Accuracy: 95.0%\n",
      "\n",
      "Evaluating family: Allaple\n",
      "Progress: 100.0% (19/19) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: AntiFW\n",
      "Progress: 100.0% (20/20) - Accuracy: 100.0%\n",
      "\n",
      "Evaluating family: AutoIt\n",
      "Progress: 100.0% (20/20) - Accuracy: 25.0%\n",
      "\n",
      "Evaluating family: BadCrypt\n",
      "Progress: 100.0% (19/19) - Accuracy: 42.11%\n",
      "\n",
      "Evaluating family: Bingoml\n",
      "Progress: 100.0% (20/20) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Debris\n",
      "Progress: 100.0% (20/20) - Accuracy: 75.0%\n",
      "\n",
      "Evaluating family: Ekstak\n",
      "Progress: 100.0% (17/17) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Khalesi\n",
      "Progress: 100.0% (20/20) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Mydoom\n",
      "Progress: 100.0% (20/20) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Picsys\n",
      "Progress: 100.0% (19/19) - Accuracy: 57.89%\n",
      "\n",
      "Evaluating family: RTM\n",
      "Progress: 100.0% (20/20) - Accuracy: 100.0%\n",
      "\n",
      "Evaluating family: Starter\n",
      "Progress: 100.0% (20/20) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Sytro\n",
      "Progress: 100.0% (20/20) - Accuracy: 0.0%\n",
      "\n",
      "Evaluating family: Vtflooder\n",
      "Progress: 100.0% (20/20) - Accuracy: 20.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_folder_loc = 'data/test_data/'\n",
    "vector_folder_loc = 'data/vectors/'\n",
    "test_data = os.listdir(test_folder_loc)\n",
    "\n",
    "# loop through the test data and analyze the traits\n",
    "results = {}\n",
    "for family in test_data:\n",
    "    print('Evaluating family:', family)\n",
    "    results[family] = {}\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    family_samples = os.listdir(test_folder_loc + family)\n",
    "    \n",
    "    for sample in family_samples:\n",
    "\n",
    "        # load the sample traits\n",
    "        sample_traits = joblib.load(test_folder_loc + family + '/' + sample)\n",
    "\n",
    "        # pre processing the sample traits\n",
    "        sample_traits = process_traits(sample_traits, 50, drop_duplicates=False)\n",
    "\n",
    "        # analyze the traits\n",
    "        result = analyze_traits(sample_traits, vector_folder_loc)\n",
    "        predicted_family = result[0]['family']\n",
    "\n",
    "        # save the results\n",
    "        results[family][sample] = {}\n",
    "        results[family][sample]['Actual'] = family\n",
    "        results[family][sample]['Predicted'] = predicted_family\n",
    "\n",
    "        if family == predicted_family:\n",
    "            correct += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Progress: {round(total / len(family_samples) * 100, 2)}% ({total}/{len(family_samples)}) - Accuracy: {round(accuracy * 100, 2)}%', end='\\r')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agentc_Trojan.Win32.Agentc.c-08546d7b075c4cbfb...</td>\n",
       "      <td>Agentc</td>\n",
       "      <td>Agentc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agentc_Trojan.Win32.Agentc.c-120832050bff552cc...</td>\n",
       "      <td>Agentc</td>\n",
       "      <td>Agentc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agentc_Trojan.Win32.Agentc.c-2368c69355e580f91...</td>\n",
       "      <td>Agentc</td>\n",
       "      <td>Agentc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agentc_Trojan.Win32.Agentc.c-442c047c60d2f0818...</td>\n",
       "      <td>Agentc</td>\n",
       "      <td>Agentc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agentc_Trojan.Win32.Agentc.c-44605e9be8d3a9972...</td>\n",
       "      <td>Agentc</td>\n",
       "      <td>Agentc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sample  Actual Predicted\n",
       "0  Agentc_Trojan.Win32.Agentc.c-08546d7b075c4cbfb...  Agentc    Agentc\n",
       "1  Agentc_Trojan.Win32.Agentc.c-120832050bff552cc...  Agentc    Agentc\n",
       "2  Agentc_Trojan.Win32.Agentc.c-2368c69355e580f91...  Agentc    Agentc\n",
       "3  Agentc_Trojan.Win32.Agentc.c-442c047c60d2f0818...  Agentc    Agentc\n",
       "4  Agentc_Trojan.Win32.Agentc.c-44605e9be8d3a9972...  Agentc    Agentc"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the accuracy, precision, recall, and f1 score\n",
    "results_df = pd.DataFrame()\n",
    "for r in results:\n",
    "    for sample in results[r]:\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(results[r][sample], index=[sample])])\n",
    "\n",
    "results_df = results_df.reset_index()\n",
    "results_df = results_df.rename(columns={'index': 'Sample'})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Agentc       0.95      0.95      0.95        20\n",
      "     Allaple       0.00      0.00      0.00        19\n",
      "      AntiFW       0.16      1.00      0.27        20\n",
      "      AutoIt       0.71      0.25      0.37        20\n",
      "    BadCrypt       0.22      0.42      0.29        19\n",
      "     Bingoml       0.00      0.00      0.00        20\n",
      "      Debris       0.60      0.75      0.67        20\n",
      "      Ekstak       0.00      0.00      0.00        17\n",
      "     Khalesi       0.00      0.00      0.00        20\n",
      "      Mydoom       0.00      0.00      0.00        20\n",
      "      Picsys       0.28      0.58      0.37        19\n",
      "         RTM       0.80      1.00      0.89        20\n",
      "     Starter       0.00      0.00      0.00        20\n",
      "       Sytro       0.00      0.00      0.00        20\n",
      "   Vtflooder       1.00      0.20      0.33        20\n",
      "\n",
      "    accuracy                           0.35       294\n",
      "   macro avg       0.31      0.34      0.28       294\n",
      "weighted avg       0.32      0.35      0.28       294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Damian Lau\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Damian Lau\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Damian Lau\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# get the classification report\n",
    "print(classification_report(results_df['Actual'], results_df['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
